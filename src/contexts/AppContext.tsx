import { createContext, useContext, ReactNode, useState, useEffect } from 'react';
import { useKV } from '../hooks/useKV';
import { 
  AppSettings, 
  defaultSettings, 
  TranscriptSegment, 
  SummaryChunk, 
  QAPair, 
  ConnectionStatus,
  RecordingState
} from './types';

interface AppContextType {
  // Settings
  settings: AppSettings;
  updateSettings: (newSettings: Partial<AppSettings>) => void;
  
  // Recording state
  recordingState: RecordingState;
  toggleRecording: () => void;
  
  // Transcript data
  transcript: TranscriptSegment[];
  addTranscriptSegment: (segment: TranscriptSegment) => void;
  clearTranscript: () => void;
  
  // Summary data
  summaries: SummaryChunk[];
  addSummary: (summary: SummaryChunk) => void;
  
  // Q&A data
  qaList: QAPair[];
  addQA: (qa: QAPair) => void;
  askQuestion: (question: string) => Promise<void>;
  
  // UI state
  activeView: 'transcript' | 'summaries' | 'qa';
  setActiveView: (view: 'transcript' | 'summaries' | 'qa') => void;
  
  // Service connection status
  sttStatus: ConnectionStatus;
  openaiStatus: ConnectionStatus;
}

const AppContext = createContext<AppContextType | undefined>(undefined);

export function AppProvider({ children }: { children: ReactNode }) {
  // Persist settings with useKV
  const [settings, setSettings] = useKV<AppSettings>('ai-assistant-settings', defaultSettings);
  
  // In-memory state
  const [recordingState, setRecordingState] = useState<RecordingState>({
    isRecording: false,
    startTime: null,
    duration: 0
  });
  
  const [transcript, setTranscript] = useState<TranscriptSegment[]>([]);
  const [summaries, setSummaries] = useKV<SummaryChunk[]>('ai-assistant-summaries', []);
  const [qaList, setQAList] = useKV<QAPair[]>('ai-assistant-qa', []);
  const [activeView, setActiveView] = useState<'transcript' | 'summaries' | 'qa'>('transcript');
  
  // Service connection statuses
  const [sttStatus, setSTTStatus] = useState<ConnectionStatus>('disconnected');
  const [openaiStatus, setOpenAIStatus] = useState<ConnectionStatus>('disconnected');
  
  // Update settings
  const updateSettings = (newSettings: Partial<AppSettings>) => {
    setSettings((current) => ({ ...current, ...newSettings }));
  };
  
  // Toggle recording
  const toggleRecording = () => {
    if (recordingState.isRecording) {
      // Stop recording
      setRecordingState({
        isRecording: false,
        startTime: null,
        duration: recordingState.startTime ? Date.now() - recordingState.startTime : 0
      });
      // TODO: Implement actual recording stop logic
    } else {
      // Start recording
      setRecordingState({
        isRecording: true,
        startTime: Date.now(),
        duration: 0
      });
      // Reset transcript for new session
      setTranscript([]);
      // TODO: Implement actual recording start logic
    }
  };
  
  // Add transcript segment
  const addTranscriptSegment = (segment: TranscriptSegment) => {
    setTranscript((prev) => [...prev, segment]);
    
    // Check if it's a question and handle it
    if (segment.isQuestion) {
      // This would be handled by the Azure OpenAI service in a real implementation
      handleQuestion(segment.text);
    }
  };
  
  // Clear transcript
  const clearTranscript = () => {
    setTranscript([]);
  };
  
  // Add summary
  const addSummary = (summary: SummaryChunk) => {
    setSummaries((prev) => [...prev, summary]);
  };
  
  // Add Q&A pair
  const addQA = (qa: QAPair) => {
    setQAList((prev) => [...prev, qa]);
  };
  
  // Handle question detection (placeholder)
  const handleQuestion = async (question: string) => {
    // In a real implementation, this would call Azure OpenAI
    const qa: QAPair = {
      id: Date.now().toString(),
      question,
      answer: 'This is a placeholder answer. In a real implementation, this would be generated by Azure OpenAI.',
      timestamp: Date.now(),
      isManual: false
    };
    
    addQA(qa);
  };
  
  // Ask question manually
  const askQuestion = async (question: string) => {
    // In a real implementation, this would call Azure OpenAI
    const qa: QAPair = {
      id: Date.now().toString(),
      question,
      answer: 'This is a placeholder answer for a manually asked question. In a real implementation, this would be generated by Azure OpenAI.',
      timestamp: Date.now(),
      isManual: true
    };
    
    addQA(qa);
    setActiveView('qa');
  };
  
  // Check service connectivity on settings change
  useEffect(() => {
    const checkSTTConnectivity = async () => {
      if (!settings.stt.endpoint || !settings.stt.subscriptionKey) {
        setSTTStatus('disconnected');
        return;
      }
      
      setSTTStatus('connecting');
      try {
        // In a real implementation, we'd make an actual API call to validate credentials
        // For now, we'll just simulate a successful connection after a delay
        await new Promise(resolve => setTimeout(resolve, 1000));
        setSTTStatus('connected');
      } catch (error) {
        setSTTStatus('error');
      }
    };
    
    const checkOpenAIConnectivity = async () => {
      if (!settings.openai.endpoint || !settings.openai.subscriptionKey) {
        setOpenAIStatus('disconnected');
        return;
      }
      
      setOpenAIStatus('connecting');
      try {
        // In a real implementation, we'd make an actual API call to validate credentials
        // For now, we'll just simulate a successful connection after a delay
        await new Promise(resolve => setTimeout(resolve, 1000));
        setOpenAIStatus('connected');
      } catch (error) {
        setOpenAIStatus('error');
      }
    };
    
    checkSTTConnectivity();
    checkOpenAIConnectivity();
  }, [settings.stt, settings.openai]);
  
  // Return context provider
  return (
    <AppContext.Provider
      value={{
        settings,
        updateSettings,
        recordingState,
        toggleRecording,
        transcript,
        addTranscriptSegment,
        clearTranscript,
        summaries,
        addSummary,
        qaList,
        addQA,
        askQuestion,
        activeView,
        setActiveView,
        sttStatus,
        openaiStatus
      }}
    >
      {children}
    </AppContext.Provider>
  );
}

// Custom hook to use the app context
export function useApp() {
  const context = useContext(AppContext);
  
  if (context === undefined) {
    throw new Error('useApp must be used within an AppProvider');
  }
  
  return context;
}